{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges for week 3\n",
    "\n",
    "Now that we've seen how to clean in Pandas, it's time for you to apply this knowledge. This week has three challenges. Make sure to give it a try and complete all of them. \n",
    "\n",
    "**Some important notes for the challenges:**\n",
    "1. These challenges are a warming up, and help you get ready for class. Make sure to give them a try. If you get an error message, try to troubleshoot it (using Google often helps). If all else fails, go to the next challenge (but make sure to hand it in).\n",
    "2. While we of course like when you get all the answers right, the important thing is to exercise and apply the knowledge. So we will still accept challenges that may not be complete, as long as we see enough effort *for each challenge*. This means that if one of the challenges is not delivered (not started and no attempt shown), we unfortunately will not be able to provide a full grade for that week.\n",
    "3. Delivering the challenge to the right place is a critical part of the challenge. This means we will only be able to grade and accept challenges that are live on your own private GitHub repository (so with a link starting with https://github.com/uva-cw-digitalanalytics/2021s1-) **and** delivered on time as a Canvas assignment. Watch the videos on Canvas on how to hand in your challenges.\n",
    "\n",
    "### Facing issues? \n",
    "\n",
    "We are constantly monitoring the issues on the GitHub general repository (https://github.com/uva-cw-digitalanalytics/2021s1/issues) to help you out. Don't hesitate to log an issue there, explaining well what the problem is, showing the code you are using, and the error message you may be receiving. \n",
    "\n",
    "**Important:** We are only monitoring the repository in weekdays, and until 17.00. Issues logged after this time will most likely be answered the next day. This means you should now wait for our response before submitting a challenge :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting setup for the challenges\n",
    "\n",
    "We will use actual Twitter data for the challenges of this week. To do so, you need:\n",
    "* To download DMI-TCAT data that you may already be collecting for yourself, or from a colleague (if you haven't requested data collection yet). Please use **the same data** that you requested sentiment analysis for\n",
    "* The sentiment analysis results (get them from SurfDrive)\n",
    "\n",
    "If you don't have sentiment analysis results, get them from a colleague (in SurfDrive), but then make sure to download also their Twitter data from DMI-TCAT - otherwise the merge won't work.\n",
    "\n",
    "**All the challenges below are with this Twitter data. Make sure to start your challenge by doing the basics of loading and inspecting the data, even if not specified in challenge itself.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "twitter = pd.read_csv(\"tcat_NuriaVila-20210207-20210208------------fullExport--9654fe3ff4.csv\")\n",
    "sentiment = pd.read_pickle(\"NuriaVila_EN_completed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "\n",
    "Create two binary variables for the Twitter data based on the text column. They should be two **meaningful** categories for your data, and they should have either the value 0 (when the tweet is not of that category) or 1 (when the tweet is of that category). \n",
    "\n",
    "Make sure to explain (in MarkDown) what these variables are, and provide some descriptives when they are done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                               int64\n",
       "time                             int64\n",
       "created_at                      object\n",
       "from_user_name                  object\n",
       "text                            object\n",
       "filter_level                    object\n",
       "possibly_sensitive             float64\n",
       "withheld_copyright             float64\n",
       "withheld_scope                 float64\n",
       "truncated                      float64\n",
       "retweet_count                    int64\n",
       "favorite_count                   int64\n",
       "lang                            object\n",
       "to_user_name                    object\n",
       "in_reply_to_status_id          float64\n",
       "quoted_status_id               float64\n",
       "source                          object\n",
       "location                        object\n",
       "lat                            float64\n",
       "lng                            float64\n",
       "from_user_id                     int64\n",
       "from_user_realname              object\n",
       "from_user_verified               int64\n",
       "from_user_description           object\n",
       "from_user_url                   object\n",
       "from_user_profile_image_url     object\n",
       "from_user_utcoffset            float64\n",
       "from_user_timezone             float64\n",
       "from_user_lang                 float64\n",
       "from_user_tweetcount             int64\n",
       "from_user_followercount          int64\n",
       "from_user_friendcount            int64\n",
       "from_user_favourites_count       int64\n",
       "from_user_listed                 int64\n",
       "from_user_withheld_scope       float64\n",
       "from_user_created_at            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the type of column \"created_at\" to datetime\n",
    "twitter[\"created_at\"] = twitter[\"created_at\"].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **first binary variable** that I want to create is the variable that can tell me whether this tweet is an original tweet or a retweet. The difference between these two kinds of posts is that the reposts start with \"RT @\", then follow with the username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2768\n",
       "1    2353\n",
       "Name: retweet, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I search for the twitter texts that start with \"RT @\". \n",
    "#Because I want to return \"0\" and \"1\", instead of \"True\" and \"False\", I set the column as integer.\n",
    "twitter[\"retweet\"] = twitter[\"text\"].str.startswith(\"RT @\").astype(int)\n",
    "twitter[\"retweet\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter[\"retweet\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result I see that in this Twitter dataset, there are 2353 retweets and 2768 original tweets. Every text is either an original post or a retweet, and there is no missing values in this variable. This is reasonable, because last time I found that there was no missing value in ```text``` column of this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to explore how many tweets contain external links. Therefore, the **second binary variable** I want to create is a varaible that can tell me whether the tweet contains \"http\" or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3587\n",
       "0    1534\n",
       "Name: ext_link, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I search for the twitter texts that contain \"http\". \n",
    "twitter[\"ext_link\"] = twitter[\"text\"].str.contains(\"http\").astype(int)\n",
    "twitter[\"ext_link\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find that in this dataset, more than 70% of the tweets contain one or more external link! Perhaps this dataset was created by the keyword \"penguin random house\", which is a publisher that has its own official website, so users can contain the website address in their posts. Also, I guess that adding keywords like \"e-book\" or \"audiobook\" may include some tweets that share the link of e-books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2\n",
    "\n",
    "Merge the sentiment analysis results with your data. Make sure to check whether the length of the dataframe generated by the merge makes sense.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before merging the dataframe, I need to select the tweets that are written in English, because in last week's challenge, I handed in a dataframe that only contains English tweets for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = twitter[twitter[\"lang\"] == \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4002"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the length of twitter dataframe\n",
    "len(twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4002"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the length of sentiment dataframe\n",
    "len(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find that the length of these two dataframes are the same, so I can now find the unique identifier and start to merge the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                      int64\n",
       "time                                    int64\n",
       "created_at                     datetime64[ns]\n",
       "from_user_name                         object\n",
       "text                                   object\n",
       "filter_level                           object\n",
       "possibly_sensitive                    float64\n",
       "withheld_copyright                    float64\n",
       "withheld_scope                        float64\n",
       "truncated                             float64\n",
       "retweet_count                           int64\n",
       "favorite_count                          int64\n",
       "lang                                   object\n",
       "to_user_name                           object\n",
       "in_reply_to_status_id                 float64\n",
       "quoted_status_id                      float64\n",
       "source                                 object\n",
       "location                               object\n",
       "lat                                   float64\n",
       "lng                                   float64\n",
       "from_user_id                            int64\n",
       "from_user_realname                     object\n",
       "from_user_verified                      int64\n",
       "from_user_description                  object\n",
       "from_user_url                          object\n",
       "from_user_profile_image_url            object\n",
       "from_user_utcoffset                   float64\n",
       "from_user_timezone                    float64\n",
       "from_user_lang                        float64\n",
       "from_user_tweetcount                    int64\n",
       "from_user_followercount                 int64\n",
       "from_user_friendcount                   int64\n",
       "from_user_favourites_count              int64\n",
       "from_user_listed                        int64\n",
       "from_user_withheld_scope              float64\n",
       "from_user_created_at                   object\n",
       "retweet                                 int64\n",
       "ext_link                                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the columns of twitter dataframe\n",
    "twitter.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          object\n",
       "text        object\n",
       "negative    object\n",
       "positive    object\n",
       "neutral     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the columns of sentiment dataframe\n",
    "sentiment.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the columns of the two dataframes, I think the unique identifiers here can be ```id``` and ```text```. However, in ```sentiment```, ```id``` is in object form. I need to change it to numeric before merging the two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the type of column \"id\" to numeric\n",
    "sentiment[\"id\"] = sentiment[\"id\"].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the dataframes\n",
    "twitter = twitter.merge(sentiment, on=[\"id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4002"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the length of the merged table\n",
    "len(twitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3\n",
    "\n",
    "The sentiment analysis results has three interesting columns: ```neutral```,  ```positive```, and ```negative```. It is coming from the SentiStrength (http://sentistrength.wlv.ac.uk/) algorithm, trinary version.\n",
    "\n",
    "For this challenge, you need to:\n",
    "1. Create one variable that summarizes the sentiment (i.e., that somehow aggregates the information of it being positive or negative - or potentially neutral - into one single variable)\n",
    "2. Using the ```.groupby``` function, compare the means and standard deviations of that variable per category (that you created in Challenge 1).\n",
    "\n",
    "*Tip: Pandas makes it easy to run numerical operations across columns. Let's say that I want to multiply the value that is in column A by the value that is in column B and store it in column C... I can simply use:*\n",
    "```df['C'] = df['A'] * df['B']```\n",
    "\n",
    "\n",
    "**Note:** if you cannot complete #1, make sure to at least complete #2 with each column separately. But do give it a try ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the website of SentiStrength does not include a clear description of how the ```neutral``` column works in the analysis, I explore the dataframe a little bit and try to find the meaning of the scores in ```neutral``` column. After reading multiple rows, I find that by adding the values in ```positive``` and ```negative``` columns:  \n",
    "* if the value for ```positive``` is 1 and that for ```negative``` is -1, the value in ```neutral``` column would be 0; \n",
    "* if the result is more than 0, the value in ```neutral``` column would be 1;\n",
    "* if the result is less or equal than 0 (except from the situation that ```positive``` and ```negative``` are 1 and -1), the value in ```neutral``` column would be -1.  \n",
    "After finding how ```neutral``` works, it would be easier for me to work on the new variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried different ways of generating the new variable:\n",
    "* If I use ```positive * negative```, I cannot tell the difference between, for example, (-4,1) and (-1,4);\n",
    "* If I use ```neutral(positive ** 2 - negative ** 2)``` or ```positive ** 3 + negative ** 3```, I cannot tell the difference between (-4,4) and (-2,2);\n",
    "* If I use ```positive ** 3 * negative ** 3```, I cannot tell the difference between (-4,5) and (-5,4);\n",
    "* If I use ```positive - negative ** 2```, I cannot tell the difference between (-1,1) and (-2,4)； \n",
    "* If I use ```neutral(positive ** 2 + negative ** 2)```, the result generated by this calculation is counter-intuitive. For example, (-1) * (-4 ** 2 + 1 ** 2) = -17, while (-1) * (-4 ** 2 + 2 ** 2) = -18. Intuitively, I would think that the post that has the value of -18 would be more negative, but actually it is more positive than the post that contains the value of -17. By using this calculation, I can tell the strength of the sentiment of the posts, but I cannot tell how strong the positive or negative sentiment is. Moreover, it is meaningless to count the mean on this value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, I come up with three ways to generate the variable, although I think none of which is perfect.\n",
    "* **Method 1**: I can use ```positive + negative```. Although, by doing so, I cannot tell the difference between (-3,2) and (-2,1), sometimes this is acceptable regarding the usage of the data. If now I use this Twitter dataset to calculate what are people's general evaluations to ebook, and whether if they would recommand the audiobooks to others, I do not need to count the difference between (-3,2) and (-2,1), as I just want to know a result, which is how likely would the ebooks be recommanded. It seems that to users who generated the posts that contain the sentiment of (-3,2) and (-2,1), it would be more unlikely for them to recommand the ebooks, because their overall evaluation is negative-leaning.\n",
    "* **Method 2**: I can assign a value manually to each of the combination. As the value for ```positive``` and ```negative``` are integers, I can combine them as ```neutral(positive.(-negative))```. In this way, the central point is 0, the sign before the value of the new variable (+ or -) shows whether the sentiment is positive or negative, and the change of the number shows how the different sentiments change. However, calculating mean and standard deviation on this value is meaningless.  \n",
    "The difficulties about assigning number is that I am not sure about how can I use one number to compare the change of two sentiments, but the assigning process in the second method actually provides me a way to compare the different combinations.\n",
    "* **Method 3**: I can reassign numbers to the result I get in Method 2. The numbers I get from Method 2 would range from -5.5 to 5.4, so I can assign -14 to 10 to different numbers. The process can be shown in the following table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Assign | Reassign |\n",
    "| --- | --- |\n",
    "| 5.4 | 10 |\n",
    "| 5.3 | 9 |\n",
    "| 5.2 | 8 |\n",
    "| 5.1 | 7 |\n",
    "| 4.3 | 6 |\n",
    "| 4.2 | 5 |\n",
    "| 4.1 | 4 |\n",
    "| 3.2 | 3 |\n",
    "| 3.1 | 2 |\n",
    "| 2.1 | 1 |\n",
    "| 0 | 0 |\n",
    "| -1.2 | -1 |\n",
    "| -1.3 | -2 |\n",
    "| -1.4 | -3 |\n",
    "| -1.5 | -4 |\n",
    "| -2.2 | -5 |\n",
    "| -2.3 | -6 |\n",
    "| -2.4 | -7 |\n",
    "| -2.5 | -8 |\n",
    "| -3.3 | -9 |\n",
    "| -3.4 | -10 |\n",
    "| -3.5 | -11 |\n",
    "| -4.4 | -12 |\n",
    "| -4.5 | -13 |\n",
    "| -5.5 | -14 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the three sentiment related vatiables to numeric\n",
    "twitter[[\"positive\", \"negative\", \"neutral\"]] = twitter[[\"positive\", \"negative\", \"neutral\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1\n",
    "twitter[\"med1\"] = twitter[\"positive\"] + twitter[\"negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 2\n",
    "#Turn negative value to positive\n",
    "twitter[\"neg\"] = twitter[\"negative\"] * (-1)\n",
    "#Combine columns “neg” and “positive”\n",
    "twitter[\"med2\"] = twitter[\"positive\"].astype(str) + \".\" + twitter[\"neg\"].astype(str)\n",
    "#Change the type of \"med2\"\n",
    "twitter[\"med2\"] = twitter[\"med2\"].apply(pd.to_numeric)\n",
    "#Multiply by neutral\n",
    "twitter[\"med2\"] = twitter[\"med2\"] * twitter[\"neutral\"]\n",
    "#Delete the column \"neg\"\n",
    "del twitter[\"neg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0    1332\n",
       " 2.1     877\n",
       " 3.1     404\n",
       " 4.1     313\n",
       "-1.2     291\n",
       "-2.2     157\n",
       " 3.2     136\n",
       "-3.3      75\n",
       "-2.3      60\n",
       "-1.3      59\n",
       " 4.2      58\n",
       "-2.4      58\n",
       "-3.4      48\n",
       "-1.4      39\n",
       " 5.1      31\n",
       " 5.2      20\n",
       " 4.3      16\n",
       "-3.5       7\n",
       "-2.5       6\n",
       "-4.4       4\n",
       "-4.5       4\n",
       "-1.5       3\n",
       " 5.3       2\n",
       " 5.4       2\n",
       "Name: med2, dtype: int64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method 3\n",
    "#Check the value in \"med2\"\n",
    "twitter[\"med2\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reassign the numbers according to the table above\n",
    "twitter[\"med3\"] = twitter[\"med2\"].replace({0.0:0, 2.1:1, 3.1:2, 4.1:4, -1.2:-1, -2.2:-5, 3.2:3, -3.3:-9, -2.3:-6, -1.3:-2, 4.2:5, -2.4:-7, -3.4:-10, -1.4:-3, 5.1:7, 5.2:8, 4.3:6, -3.5:-11, -2.5:-8, -4.4:-12, -4.5:-13, -1.5:-4, 5.3:9, 5.4:10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1**: ```Positive + Negative```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retweet\n",
       "0    0.471549\n",
       "1    0.685145\n",
       "Name: med1, dtype: float64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.groupby([\"retweet\"])[\"med1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retweet\n",
       "0    1.224700\n",
       "1    1.306298\n",
       "Name: med1, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.groupby([\"retweet\"])[\"med1\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ext_link\n",
       "0    0.510841\n",
       "1    0.594946\n",
       "Name: med1, dtype: float64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.groupby([\"ext_link\"])[\"med1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ext_link\n",
       "0    1.270702\n",
       "1    1.265711\n",
       "Name: med1, dtype: float64"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.groupby([\"ext_link\"])[\"med1\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the calculation I find that, \n",
    "* for this Twitter dataset, the mean sentiment of retweets have more positive sentiment than the original posts on general. This may indicate that people are more likely to repost tweets that contain positive emotions. However, the mean sentiments for both the retweet group and the original post group are not high, and are more close to neutral;\n",
    "* some retweets contain stronger positive and negative emotions, since the standard deviation for retweets are higher (though slightly);\n",
    "* for the posts containing or not containing the external link, the mean sentiments are similar. To me, this result is reasonable, because the external link is a way to add information to tweets, not add emotions;\n",
    "* the standard deviations for the two groups are also similar, indicating that the tweets in two categories both contain positive and negative emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2**: ```Neutral * (Positive.(-Negative))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retweet\n",
       "0    0.851679\n",
       "1    1.070560\n",
       "Name: med2, dtype: float64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.groupby([\"retweet\"])[\"med2\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retweet\n",
       "0    1.906975\n",
       "1    2.246714\n",
       "Name: med2, dtype: float64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.groupby([\"retweet\"])[\"med2\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ext_link\n",
       "0    0.942845\n",
       "1    0.957529\n",
       "Name: med2, dtype: float64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.groupby([\"ext_link\"])[\"med2\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ext_link\n",
       "0    2.007664\n",
       "1    2.100936\n",
       "Name: med2, dtype: float64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.groupby([\"ext_link\"])[\"med2\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 3**: Reassignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retweet\n",
       "0    0.190765\n",
       "1    0.144241\n",
       "Name: med3, dtype: float64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.groupby([\"retweet\"])[\"med3\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retweet\n",
       "0    2.616129\n",
       "1    3.468401\n",
       "Name: med3, dtype: float64"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.groupby([\"retweet\"])[\"med3\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ext_link\n",
       "0    0.188205\n",
       "1    0.161460\n",
       "Name: med3, dtype: float64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.groupby([\"ext_link\"])[\"med3\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ext_link\n",
       "0    2.780787\n",
       "1    3.141095\n",
       "Name: med3, dtype: float64"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.groupby([\"ext_link\"])[\"med3\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, the means and standard deviations of the overall sentiment calculated by using number assignment are meaningless, as through the process of assigning number manulally, the variables turn to categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
